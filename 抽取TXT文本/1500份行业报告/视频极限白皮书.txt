







数字化、智能化正在开启新一代信息革命。无处不在的显示、无处不在的联接成为ICT基础设施产业的重要元素，而人们对体验需求的升级正在加速这一场变革。在信息传递的过程中，视觉接收方式占据信息接收的主导地位，因此，提升视觉信息体验成为重中之重。从显示技术上看，人们经历了从传统标清到高清再到超高清4K的演变，色彩更真实丰富，图像更加清晰，人们甚至可以清楚的看到画面中皮肤上的汗毛。即便如此，京东方8K大屏已然出现，分辨率进一步提升，在追求极致、探索无所不在的显示路上引领行业发展。然而，平面技术的极致体验依然无法满足人类的体验需求。在数字世界，沉浸式VR将成为通往数字世界的入口。人们在虚拟环境中不仅要满足360°全景观察的诉求，还需要实现自由移动并产生互动，从而虚实难辨。当前，VR尚处在入门阶段，距离极致体验还有较长距离，有待产业和技术协同发展，共同打造高度真实的虚拟世界。


双G（千兆家宽/5G）网络将以更快的传输速度、超低的时延，推动商业数字化发展在双G网络时代，商业发展将呈现四个显著特征。首先，大数据使巨量数据分析与信息洞察成为可能，使信息提炼结果更具规律性和通用性。其次，边缘计算架构将消除跨地域的数据共享壁垒，为机器学习的应用普及提供基础环境。第三，数据开放平台快速发展，促进信息聚合和共享，从而产生更多价值。第四，作为信息传递的最后一环，数据可视化需求将快速增加，人机交互将从低维到多维显示发展，从标清向超高清发展，从视觉交互向多维度感官交互发展，从而更符合人类自然交互习惯。回首过去，伴随通信技术的进步，在市场和政府的双轮驱动下，中国网络实现跨越式发展。以华为技术有限公司（文中简称“华为”）为代表的通信技术企业，为通信技术的快速发展作出了不懈努力，是社会的变革与商业的重塑的基石。可以预见，在更强的通信基础上，边缘计算、大数据、人工智能等前沿技术的发展将再一次重塑人们的生活。与此同时，显示技术的发展一直默默支持中国通信产业和工业的崛起。从CRT产品依赖进口到LCD技术大规模本土量产，再到柔性OLED技术应用，在短短二十几年中，中国经历了从缺芯少屏到自主研发的跨越式发展。京东方科技集团股份有限公司（文中简称“京东方”、“BOE”）作为国内代表性的显示科技公司，从LCD显示技术入手，自主开发多种显示技术，并积极拓展人机交互维度，支撑中国通信和电子科技产业稳步崛起。通信技术与人机交互技术相辅相成，在双G网络时代，超高带宽与显示交互必将成为推动社会进步和商业变革的砥柱与桥梁。本白皮书由京东方、华为、信通院联合出品，从视觉体验需求角度探索视觉信息发展的极限，对未来发展趋势进行洞察和预测，从业务场景角度探索网络背后的指标诉求、解决方案等可能性。希望本白皮书有助于激发行业伙伴对视觉体验信息的思考，为产品竞争力构筑带来价值，同时华为iLab愿与产业链各位同仁一起深入探讨，共同为视觉极限逼近信息极限不断努力。


人接收到的大部分信息都是通过视觉的方式，根据人眼视觉体验需求，显示技术可以分为三个阶段：平面显示、VR三维沉浸显示、光场显示。平面显示阶段，4K/8K已经接近人眼极限，未来在色域、帧率、平面3D显示技术等方面可以做进一步优化，提供更好地视觉体验。本报告列举了一些行业观点和产业数据，表明整个显示行业正处于蓬勃发展期：若保持价格不变，显示产品性能每36个月需提升一倍以上，这一周期正被缩短；而在通信领域，光纤容量每36个月翻一倍，IP网络性能每18个月翻番。显示领域和通信领域正重定义摩尔定律、挑战香农极限，共同推动数字化视觉体验不断逼近人眼视觉极限。按照过去显示产业的发展历程，产品分辨率每4年一个导入期：2006年-2010年是FHD2K的导入期；2012-2016年，UHD4K的渗透率达到了40%，是4K的导入期；而2018年是8K元年，预计2022年65寸以上UHD8K渗透率将会超过20%。双G时代，通信能力的提高将为超高清显示应用提供基础支持，2K内容将成为基础视频和显示需求，而4K将成为主流视频与显示需求，8K将成为体育赛事、大型直播、电影等众多视听享受的主流应用场景，8K显示也将成为高端消费电子产品新的标杆。2020年以前，VR以FASTLCD为最优显示方案，以60Hz以上刷新率配合5ms以内响应时间，有效改善晕眩感，满足VR显示苛刻需求，降低VR硬件成本。之后，随着光学技术发展，VR显示技术将以MicroOLED为最佳方案,其＜0.1ms响应时间，完美解决延时眩晕，＞80%的高色域及10000:1高对比度呈现完美显示效果，同时大大降低整机重量，带来更加舒适的用户体验。
VR可以提供三维沉浸式视觉体光场可以真实还原现实场景，进一步提升视觉体验，但光场技术成熟度不高，从内容采集制作到终端显示，整个产业还有很大发展空间。
验，但分辨率是目前发展最大的阻碍，极致体验的VR需要PPD在60以上，即显示终端分辨率达到12K（双眼），内容全景分辨率达到24K，而目前业界水平只能达到20PPD。


从平面视觉到VR/AR，再到光场，显示技术越先进，其技术成熟度越低，离满足人眼视觉极限越远。但毋庸置疑，VR/AR、光场是未来最理想的显示方式，更高分辨率的VR、更多层深度信息的光场，将给用户带来逼近现实世界的视觉体验。与此同时，极限的视觉体验会带来巨大的数据量，给网络传输带来挑战：平面视觉阶段：运营级4K需要50Mbps带宽，极致级4K需要75Mbps，考虑家庭多屏并发，网络需求将达200Mbps。随着平面视觉体验向沉浸视觉体验迈进，CloudVR从全景8K分辨率起步，家庭宽带需向千兆演进，现有网络也将面临挑战，家庭Wi-Fi需要优化，GPON需要向10GPON升级，对于强交互类业务，需要通过CDN下沉和边缘计算来保障时延，网络架构有必要开展重构。未来沉浸视觉体验向全息光场等维度演进，将带来数据的数量级增长，需要后双G时代的网络，如万兆或太兆家庭宽带/6G的支撑。概要


在人类体验到的信息中，83%来自视觉。随着视频娱乐不断普及，各种数字画面充斥着人们生活，而视觉信息需要海量的数据，从图像到视频再到VR、光场，从标清、高清到超高清，人类对视觉体验的追求逐步提升，那么提升到何种程度才能接近人眼的视觉极限呢？如果以正常人眼看现实世界的体验为基准，视觉极限就是在画面清晰度、色彩饱和度和显示时延等方面，使人眼已无法分辨出数字化内容与看现实世界的差异，这与人眼视觉特性密切相关。人眼有两种感光细胞：杆状细胞和锥状细胞，其中杆状细胞负责单色夜视，锥状细胞负责色彩视觉。人眼能够感知波长在380~780纳米的可见光，并对不同波长的光有不同的敏感度，实验表明，白天人眼对波长555纳米的光敏感度最高，所以人眼感觉红色和紫色是偏暗的，感觉最亮的是黄绿色。夜间视敏度曲线会稍微左移。色彩的数量可以用色深来表示，如色深8bit，即将灰度值在0~255之间分成2的8次方——256个阶级，能够展现256种颜色。而人眼可以分辨超过千万种颜色，所以需要24位的色深才能达到人眼色彩分辨极限。


人眼除了对色彩的分类有感知外，对色彩的强度也有感知，物体单位面积的发光强度用亮度（单位尼特，nit）来表示，人眼对亮度的感知范围大约在10~10nits之间。亮度为3000nits时，人眼可以较舒适地观看物体，这接近白天阳光照射下自然环境的亮度。人眼能感知的亮度范围很广，但实际上是无法在同一时间观看包含过高和过低亮度的同一画面，这就引出对比度的概念，即发光面的最大亮度与最小亮度之比。人眼能承受的对比度范围约1000:1（亮度适中时）~10:1（亮度极高或极低时），电影银幕对比度大约为100:1。人眼可观看的角度很广，大概124°，可集中注意力观看的区域范围约25°，60°是最舒适的观看区域范围。人眼对物体的细节分辨能力也很强，在1.0视力下，分辨能力可达60PPD（PixelPerDegree），即可以分辨1公里处相距30厘米的两个物体。人眼感觉的连续性是活动画面的前提，当有光刺激人眼时，从视觉画面的建立到消失需要一定时间，即视觉惰性。人眼的视觉惰性约0.05~0.2s，所以只要保障画面刷新频率大于20Hz，人眼即可看到连续的活动画面，这也是电影帧率为24fps以上的依据。24帧只能保障画面连续，若要好的视觉体验，需要60fps、90fps、甚至120fps的帧率，如VR/AR这类时延敏感型业务，必须确保帧率在60fps以上。深度感知是人眼最重要的特性之一，人眼之所以能感知立体空间或物体，是因为人双眼成像存在一定视差，带视差的两幅图像经过人脑合成后，将会呈现立体视觉，从而能够感知物体的深度信息。


根据业界公认研究，人眼能够感知立体视觉的原因主要包括心理感知、移动视差和聚焦模糊等。心理感知所谓心理感知，顾名思义，即人眼看到的不一定是三维物体，但通过某种手段“欺骗”了大脑，使大脑产生了三维立体效果的“错觉”，该种“手段”包括：
仿射：即近大远小，人眼去看同样大小的物体，近处的物体在人眼中成像越大阴影：光线照射下，物体产生的阴影可以辅助人眼判断物体的立体形状，如一个球体和一个圆柱体，人眼正对看过去，获取的都是一个圆形画面，无法区分其形状，但此时如果从侧面加上光照产生阴影，人眼可根据阴影轻松的判断出球体和圆柱体双目视差：同一物体，在人的左右眼中成像是有偏差的，利用这一特性，即使是平面图像，只要使左右眼看的画面存在一定视差，就可“骗过”人头脑，产生立体视觉效果，视差越大，立体效果越明显，3D电影就是使用该原理
遮挡：在同一视线内，近处的物体会挡住远处的物体，人眼可以通过遮挡关系来判断物体的相对位置关系先验先知：人脑有学习和记忆的功能，对于在现实世界中接触过的物体，即使通过二维画面展示，人脑也能自动脑补出它的三维立体效果


通过这些心理暗示，可以使平面显示产生三维效果，如手机、电视等屏幕，但其展现方式始终是平面显示，并没有真正展示出三维物体或模型。在现实世界中，人眼从不同的角度去观察物体，会获取物体不同的视觉画面，也正是因为有移动视差，人脑能判断出该物体的形状、大小等信息，最典型的应用就是VR，虽然VR的成像原理还是双目视差，但不同的是，3D电影中无论观众怎么移动位置，看到的画面总是一个视角，而在VR中，用户可以任意移动，看到不同视角的画面。心理感知可以产生三维立体“错觉”，而移动视差、聚焦模糊可以提供逼近人眼感知现实世界的立体视觉。所以，从视觉体验需求的角度，显示技术可以分为三个阶段：平面视觉显示、VR三维沉浸式显示和光场显示，并且在每个阶段，显示技术都朝着逼近人眼视觉极限的方向发展。
VR的视觉体验已经很逼近现实世界了，既有移动视差也有双目视差，但在现实场景中，人眼聚焦近处物体时，远处物体会变得模糊，反之亦然，这是VR提供不了的特性——聚焦模糊。在VR中，用户无论聚焦远处或近处，其聚焦的平面始终是VR显示屏，这会使人脑产生深度感知冲突，从而引发晕眩等反应。光场显示是解决该问题的最佳方案，因为光场可以记录光线的方向信息，从而提供物体不同深度的画面。


对于平面显示，手机、pad等小屏，2K/2.5K的分辨率就能达到人眼视觉分辨极限，而大屏电视需要4K/8K的分辨率。目前从分辨率的角度来看，平面显示已接近人眼的视觉极限了，但其他参数仍在不断优化，如更广的色域、更高刷新率、对比度等，从各个维度逼近人眼视觉极限。平面显示技术的应用场景很广，最早的平面显示场景是胶卷电影，通过灯光将胶卷上的图像投射到幕布上，实现电影的放映。随着CRT显示器（阴极射线显像管）的出现，图像记录实现的数字化，CRT显示器最典型的应用就是当时的黑白电视、彩电，以及较老的台式显示器等，这种显示器的屏幕在水平和垂直方向上都是弯曲的，这种弯曲的屏幕造成了图像失真及反光现象，视觉体验较差，并逐渐被淘汰。目前较常见的显示技术主要包括LED（发光二极管）、LCD（液晶显示）。LED是一种通过控制半导体发光二极管发光来显示图像的显示方式。LED显示屏亮度高、寿命长、视角大，并且可以实现任意延展、无缝拼接，主要用于室内外大屏广告牌等场景；LCD是通过旋转液晶像素中的液晶分子偏转角度来显示不同画面的，模块化以及芯片的高集成化设计直接降低了电路的功耗，发热量也非常小，同时LCD产品较轻薄，并且可以提供较高质量的画面，目前是市场上的主流显示技术，广泛用于手机、电视、电脑等显示屏。人眼对视觉体验的追求是永无止境的，在手机小屏领域，OLED技术可以提供比LCD更广的色域、更高的对比度，并且逐步应用到高端旗舰手机；在大屏领域，MicroLED技术（LED微缩化和矩阵化技术）实现微米级的像素间距，每一个像素点能单独控制和驱动，它的分辨率、亮度、对比度、色域等性能参数更加优秀，但目前MicroLED技术才刚起步，还没有实现量产。
若保持价格不变，显示产品性能每36个月须提升一倍以上。这一周期正被缩短。BOE创始人、董事长


研究显示，在每度视角内，像素数量达到60以上时，人眼将感觉不到颗粒感和纱窗效应，即PPD>60。PPD的大小与人眼观看屏幕的视场角、屏幕像素数量有关：在平面显示领域，手机和电视是普及度最高的显示设备，一般手机屏幕离人眼约30cm，而电视屏幕距人眼约2.5m，他们的使用场景如下表所示：
其中FOV表示人眼在水平或垂直方向看屏幕的视场角，px表示该方向的像素数量。


典型场景下，目前主流6英寸、2.5K分辨率的手机PPD能达到102，55寸、4K电视的PPD更是达到148，均满足60PPD的分辨需求。当然，对于电视，55寸并不能提供极致的家庭影院体验，100寸、120寸的超大电视屏幕将逐渐进入家庭，此时需要8K的分辨率才能达到原先55寸、4K的视觉效果。为推动8K产业发展，京东方（BOE）提出“推广8K、普及4K、替代2K、用好5G”的“8425”战略，加速构建8K超高清产业生态系统。并且从2017年开始京东方已经向华为等客户交付了110英寸8K、75英寸8K等大尺寸超高清显示屏。虽然在分辨率上，无论手机小屏还是电视大屏均达到人眼分辨极限，但从视觉体验的角度分析，屏幕的色域、刷新率、对比度等参数还存在进一步优化的空间，如HDR（高动态范围图像）、4K@144Hz等：2018年称得上是HDR显示器的元年，HDR是一种图像增强技术，可以让画面暗部更加深邃但不丢失细节，亮部更加明亮但依然真实，同时增加了画面的对比度和色域范围。手机屏幕显示技术以液晶显示(TFT-LCD)技术为主。近年来，新型技术有源矩阵有机发光二极管（AMOLED）在手机领域获得较快的发展，成为高端手机市场青睐的技术，目前各品牌中高端机型均逐步使用AMOLED屏幕。同时AMOLED技术拥有柔性显示的潜力特质，随着周边配件的技术逐步完善，在未来AMOLED柔性屏幕拥有进一步快速增长的空间。LCD仍是电视大屏主流技术电视屏幕显示技术以液晶显示（TFT-LCD）为绝对主流，占据几乎全部市场份额；新型技术AMOLED具备较好的色彩表现能力，但目前受限于良率及成本等因素，在终端消费市场仍处于探索阶段，整机价格远高于同尺寸LCD产品，距离大规模推向终端市场仍需要一段时间。在电视领域可以预见的未来内，仍将以TFT-LCD技术为主流，但技术持续进步，2018年是8K元年。元年的概念就是导入期，按照过去显示产业的发展历程，产品分辨率每4年一个导入期：2006年-2010年是FHD2K的导入期；2012-2016年，UHD4K的渗透率达到了40%，是4K的导入期；而2018年是8K元年，预计2022年65寸以上UHD8K渗透率将会超过20%。
早在2017年，为了追求极致体验，电竞行业推出了1080P@240Hz刷新率的显示器，2018年，更是实现了4K@144Hz，实现了高分辨率下刷新率的提升。


平面显示技术已经比较成熟，但对应的高质量内容还比较缺失，主要是因为高质量内容制作周期长、成本高，尤其是CG类，后期渲染对计算资源的消耗特别大，如《阿凡达》，画面渲染时使用了4000台服务器，耗时长达1年。随着4K、8K等超高清技术的普及，传统的媒体生产行业更是面临冲击，媒体生产从现场摄录、存储、传输到分发，都需要进行技术革新。为了应对传统媒体制作的各种挑战，媒体生产云化将是必然趋势。媒体生产云化是将原始采集的音频、视频信息通过专线上传到云端，云服务器能够提供性能强大的云端大集群计算机，使录制的4K/8K视频能够直接在云端进行高效剪辑，最终传输至用户终端。除了在云端进行内容编辑外，还可以将原先低分辨率、低帧率的素材，通过云端画质增强的方式提高分辨率和帧率，以提升画面质量。视频画质增强是利用插帧与超分辨率提升视频视觉效果的技术，视频的插帧利用相邻帧间的时域信息演算出一个过渡帧来提升视频的流畅性，而超分辨率则是利用空域信息计算出插值像素来提升分辨率。3D显示能带来比2D显示更好的视觉体验，也是未来平面显示技术发展的重要方向。对于3D内容制作，一方面可以在制片时，就按照3D片源的方式去制作，另一方面，对于一些以往的经典2D片源，可以通过2D转3D技术实现3D视觉效果。
泰坦尼克号》是比较典型的2D转3D案例，2D电影上映时就获得了观众的好评，但其中大多数场景如果采用3D显示将带来更震撼的视觉效果。在2012年，利用转换技术制作的3D《泰坦尼克号》上映了，其2D转3D耗时超过2年，因为需要人工一帧一帧地去抓画面的深度信息，工作量很大且繁琐。但随着近些年人工智能技术的崛起，可以将AI应用到2D转3D技术中，大幅提升转换效率，从而带来更多的优质3D片源。3D片源的数据量是普通2D片源的2倍，在特殊的压缩算法下，3D片源的网络带宽需求将是普通2D片源的约1.5倍。借助云计算、AI等新技术，可以将复杂的计算从本地迁移到云端，从而降低内容制作成本、提升效率，但同时，原始素材上传云服务器会带来较大的上行网络诉求。


2016年李安导演的电影《比利林恩的中场战事》采用了4K3D120fps的形式，刷新了电影界的新高度，也是迄今为止唯一一部4K3D120fps电影。一般电影仅有2K25fps，而这部电影李安导演选择突破性的4K120fps，这不仅仅是画面质量上的提升，更是希望通过如此高清的场景，让观众真正走进战争，以士兵的角度去看所有的枪击、爆炸和受伤。对于生在和平年代的我们，会觉得战争是多么遥远，和平来的理所当然，而4K3D120fps的展现形式能够仿佛将我们置身战场，并将战争带来的恐惧、死亡表现地淋漓尽致，让更多的观众对战争有了全新的认识。2019年MWC，BOE和华为联合进行了折叠手机投屏和8K+5G直播展示，一方面用华为折叠手机MateX通过5G信号实时播放在线4K内容投屏至BOE110英寸8K超高清显示屏，另一方面用8K超高清摄像机实时拍摄巴塞罗那东海岸的风景，通过5G超高速远距离传输到BOE110英寸8K超高清显示屏实现了8K+5G的完美直播，充分展示了极致的视觉体验。高分辨率、高帧率、3D的展现形式不仅可以带来更好的视觉体验，更有助于表达影视内容传递的理念，这是未来平面视觉发展的主要趋势。平面显示技术逐渐成熟，而借助云计算，像《比利林恩的中场战事》这样的高分辨率、高帧率的内容将越来越多，平面显示逐步逼近人眼视觉极限。双G时代，通信能力的提高将为超高清显示应用提供基础支持，2K内容将成为基础视频和显示需求，而4K将成为主流视频与显示需求，8K将成为体育赛事、大型直播、电影等众多视听享受的主流应用场景，8K显示也将成为高端消费电子产品新的标杆。
图4-2华为MateX+BOE110”8K投屏
图4-3华为5GCPEPro+BOE110”8K直播


虽然平面视觉也可3D成像，但其不能提供移动视差，即用户在不同角度观看画面相同，体验不够真实，而VR能够给用户提供三维沉浸式体验，从观影形式上开辟出一条新的视觉极限之路。影响VR体验的因素很多，包括视场角、色域、刷新率、屏幕响应时间、分辨率、3DOF/6DOF等，其中分辨率是目前影响VR体验的首要因素。VR对分辨率要求极高，全景8K的VR内容才相当于传统480P电视观看体验，若要达到4K观影体验，需要VR全视角分辨率达到24K。VR头显的核心元器件只有2个：透镜和屏幕。凸透镜成像时，一倍焦距分虚实，二倍焦距分大小，当物体在透镜一倍焦距以内时，会呈正立放大虚像，也就是通常的放大镜。VR的显示就是利用放大镜原理，屏幕离透镜很近，保证在透镜的一倍焦距以内，这样人眼在透镜另一侧就可以看到屏幕里内容的放大场景。
2020年以前，VR以FASTLCD为最优显示方案，以60Hz以上刷新率配合5ms以内响应时间，有效改善晕眩感，满足VR显示苛刻需求，降低VR硬件成本。之后，随着光学技术发展，VR显示技术将以MicroOLED为最佳方案,其＜0.1ms响应时间，完美解决延时眩晕，＞80%的高色域及10000:1高对比度呈现完美显示效果，同时大大降低整机重量，带来更加舒适的用户体验。


鉴于特殊的显示方式，VR对屏幕的刷新率、响应时延、视场角、分辨率等都提出了更高的要求。屏幕刷新率过低、响应时间过长会使用户产生晕眩感，入门级VR需要屏幕刷新率在60Hz以上，响应时延在5ms以内。目前，市面上大部分VR头显屏幕的刷新率可以做到90~120Hz，响应时延控制在3ms以内，均可满足指标。VR是一种沉浸式体验，所以视场角是一个很关键的因素。人眼正常视场角约110°，若VR头显的视场角小于人眼视场角，会看到画面周围存在黑边，严重影响视觉体验。现在大部分VR头显视场角均可达到100°以上，有的甚至达到200°，所以目前视场角对VR的体验影响不大。当前VR最突出的问题是清晰度，画面存在颗粒感和纱窗效应。VR画面不清晰的原因主要有两个方面：第一，VR的内容需要均匀分布在360°，而人眼只能看到其中约110°，会丢失掉一部分像素；第二，VR画面充斥整个视场角，每个视场角分配的像素点(PPD，指每一度所包含的像素)较常规显示产品更小；而VR屏幕尺寸很小，而在小尺寸屏幕上做出高分辨率，技术要求很高。目前VR屏幕仅有3K~4K，能够承载8K分辨率内容，但视觉体验上只有传统480PTV的效果。从表中可以看出，8K内容的PPD仅有21，而人眼需要60以上PPD才无法感知到画面颗粒，所以16K分辨率是VR屏幕的发展目标，此时的VR视觉体验等效于传统TV的4K效果。


除了整体提升屏幕清晰度，还可以根据人眼特殊的生理结构来优化显示效果。人眼黄斑中央有一凹陷区域，叫做中央凹，中央凹是视网膜中视觉最敏锐的区域，相比周围区域有更强的分辨力，而中央凹的敏感角度约5°。根据这一特性，可以提高VR屏幕中间区域清晰度，并适当降低周围及边缘区域的清晰度，保障视觉体验的同时降低了屏幕的技术门槛。入门级VR设备屏幕像素密度大概在500PPI，消费级大概需要达到800PPI，OLED和LCD均可以满足需求。但如果想要达到专业级水平，屏幕需要达到1600PPI以上，此时LCD更有优势。未来主要还是在MicroOLED，它可以达到3000PPI以上，响应时间控制在1毫秒以内，可以满足未来VR/AR产业发展的需要。


对于VR/AR行业，2016~2017年后整个产业迅速发展。回顾历史，在2017年VR/AR这类近眼小屏像素密度在500~700PPI，分辨率为2K，2018年达到800~900PPI，分辨率3K，而今年，预计VR/AR屏幕会到达1000PPI以上，分辨率达到4K，并且刷新频率会提升到120Hz的水平。作为显示行业的领导者，京东方已经发布的5600PPI以上的基于MicroOLED技术的近眼小屏，未来应用到实际VR/AR产品中，会进一步提升VR/AR的视觉体验。相对传统视频内容，VR能够给用户带来纯虚拟的沉浸式体验。VR内容的呈现可以分为三种情况：传统片源、实景拍摄拼接和3D建模渲染。传统的2D/3D片源也可以通过VR的形式去观看，这就是VR巨幕影院。该种内容呈现形式虽然依托现有片源，但可以提供超越传统观影的大屏视觉体验，目前巨幕影院已成为市面上VR头显的基本功能。


实景拍摄拼接主要用于VR360视频制作，其原理是将多个相机分布在一个球面上，然后控制所有相机同步、同帧率拍摄，最后将每个相机在同一时间拍摄的画面进行拼接，形成一个球面的视频。目前VR360相机已经可以实现全景24K分辨率拍摄，但受限于终端芯片的解码能力，VR内容还停留在8K阶段。VR360视频与传统视频仅仅是观看形式不同，格式还是采用传统的视频格式。如果在传统视频播放器上播放VR360内容，那么实际观看到的是将球形画面展开的矩形画面，只有在VR设备上才能观看到全景的视频画面。VR360视频可以带来沉浸式观影体验，但需要极高的视频分辨率，全景8K的观影体验仅仅相当于观看480P的传统TV，若要达到观看4KTV的体验，需要全景分辨率达到24K，网络传输需求将达到Gbps级别。3D建模渲染主要用于VR游戏或动画制作，首先在客户端内会预先建好素材模型，用户在体验时，VR头显或外部定位器会实时采集人的动作、姿态、指令等信息，然后渲染出当前人眼视场角内的画面并显示。该种方式可以给用户提供6自由度沉浸式体验，使用户“畅游”在虚拟世界之中。


VR的应用场景很多，如体育赛事直播、VR影院、VR360视频、VR社交、VR游戏等，并且有着广阔的市场发展空间，硬件销售是VR最直接的商业模式，除此之外，还可以通过增值服务费（如赛事直播中，VR的观看方式额外收费等）、广告植入等方式实现营收。所以，未来VR产业有着较好的发展前景。VR能够给用户提供三维沉浸式体验，但当前VR的视觉体验处于入门阶段，其屏幕分辨率和内容分辨率都需要提高。2018年MWC，BOE和华为联合展示了8KVR环绕效果，这是世界上首次展示成熟的8KVR显示解决方案，8KVR显示解决方案通过提高分辨率从而消除纱窗效应，营造了更加自然真实的沉浸感，极大的改善了VR的用户体验。


在今年CES大会上，众多VR厂商展示了他们新一代VR产品，如创维的V901、PICO的G24K、DEUS的Odin等，其屏幕分辨率全部达到4K，相比2018年的3K，分辨率提升了30%。根据华为iLab研究，4K的屏幕需要匹配全视角8K的内容，所以，随着今年VR屏幕分辨率的提升，将促进更多8KVR内容的生产。更高分辨率的VR内容制作过程中，其拼接、建模、渲染等步骤对终端的计算能力要求极高，云计算将是VR内容制作的最佳选择，CloudVR是VR发展的最佳形态。除了头戴式VR，裸眼VR也逐渐应用在一些商场等公共场所。裸眼VR是通过三面、或五面LED屏幕封闭出一个密闭的立体空间，用户在该空间内不需要借助头显等设备即可感受到三维沉浸式的立体视觉效果。


对于2D平面图像，人眼只能通过遮挡、阴影、仿射等产生立体“错觉”；对于VR/AR，人眼可以通过双目视差实现三维立体视觉体验，但VR/AR显示的场景无论远近，目前都只能聚焦在一个固定距离的平面，长时间使用会使人眼产生疲倦。未来，显示交互中的信息量越来越大，全息交互将是显示交互的最终模式。从目前的技术来看，最有可能通过光场技术实现全息显示。光场是指光在每一个方向通过每一个点的光亮，可以记录和呈现现实场景中不同物体的不同光学深度，并在视觉上完美地重现三维场景。光场的数据采集量很大，包含物体表面反射出光的强度和方向信息，所以后续渲染和图像生成的发挥空间很大，能够获取物体在不同视角、不同光线条件下的图像。光场内容有多种显示方式，可以通过普通屏幕来展示，也可以通过VR/AR，甚至裸眼全息的方式来展示。普通平面显示普通二维平面显示是最简单的光场显示方式，它可以通过一个或多个平面屏幕显示不同景深、不同视角的图像，所需数据量为普通平面视频的N倍（N为屏幕数量）。该种显示方式对渲染的技术和显示技术的需求相对较低，也是光场应用最容易落地的显示方式。如在安防领域，可以用光场相机代替传统相机，相对单幅画面，光场的多视点、多景深画面可以更好地辅助人工或者智能监控。VR/AR光场显示借助VR/AR，光场可以呈现三维立体效果。使用多个相机围绕物体从不同方位进行拍摄，可以对物体进行3D建模，然后通过光场渲染算法，获取不同视角下物体表面的光线信息。对于用户，可以在VR、AR内围绕物体从各个角度去观看，并感受光线变化带来的真实感。该种光场显示方式可以应用于产品营销、物品（如古董等）展示、网红直播等场景：如果用户对某一产品感兴趣，就可以通过光场显示的方式去了解产品的各个细节；同样，在直播场景，有了光场，观众与网红不再是隔着屏幕面对面坐着，而是可以从各个角度与网红互动。


除了像物体展示这样的由内向外光场展示外，还可以由外向内展示，最典型的应用就是Google发布的光场内容《Welcometolightfields》，用户可以借助VR头显在一定球形区域内向外观看场景，这个球形区域就是光场采集的球面相机所占空间。同样，用户改变视角时，光线也会随之变化。该种光场显示方式可以用于VR旅游等场景，给用户提供更真实的视觉体验。采用VR/AR显示技术，如果将光场记录的所有数据全部传到VR/AR头显或者本地电脑，再由本地终端进行实时渲染计算呈现出来，对本地终端的存储空间和实时渲染计算能力都提出了非常高的要求。故此种显示方式，云化的存储及渲染计算将是主流方式。由云端服务器进行实时渲染计算，将计算后的用户当前视角的画面通过网络实时传输到VR/AR终端，呈现给用户。此时网络需求约几百兆。由于与云端实时交互，用户转头后需要及时将新视角的画面呈现出来，对网络时延要求非常高，云端至终端网络RTT20ms以内（未包括采集端至云端的时延）是起步阶段基本要求。全息光场显示借助VR/AR，已经可以实现三维立体多视角的光场显示，但佩戴头显，与裸眼看真实世界，体验上还是存在一定差距。未来裸眼全息是光场显示最佳形态，但该项技术成熟度很低，仅存在于实验室demo阶段，离商用普及还有一段距离。现阶段的全息光场显示方式主要包括全息膜、多视点光场显示等。要达到较清晰的效果，全息膜显示所需数据量比传统2D平面显示要大很多，根据叠境数字科技有限公司研究，一路4K分辨率全息显示数据量达到600Mbps；多视点光场显示技术，是通过多个子视图呈现立体效果，所需数据量为N*单个子视图的数据量（N为子视图个数；单个子视图数据量与子视图分辨率相关，若达到4K，每个子视图的数据量将达到几十Mbps）。实验室中的多视角投影阵列等，其所需数据量类似于此。当然，多个子视图间会有较多冗余重叠数据，随着压缩技术的发展，网络传输数据量可以大幅节约，但对终端的解码能力的要求将大幅提升。而要实现类似《阿凡达》中展现的三维超高清全息成像，数据量将达到Tbps数据级。目前，显示技术企业均积极布局全息显示技术，现阶段结合光场技术、空间光调制技术光学衍射技术，配合眼动追踪技术，已经可以借由LCD屏幕完成简单的多视角、多焦点、裸眼3D显示技术，并逐步接近全息显示交互理论效果。


光场内容的制作需要专业的光场相机。传统相机只能记录光线的(x，y，z，λ，t)信息，其中(x，y，z)表示光线的位置信息，λ表示光线的波长，t表示光线随着时间的推移会发生变化；而对于光场相机，除了记录这五个维度的信息外，还可以记录光线的方向信息，即(x，y，z，θ，φ，λ，t)7个维度的信息，其中(θ，φ)分别为光线与水平平面和垂直平面的夹角。所以，相对传统内容制作，光场内容制作需要记录和处理更多的数据量。
光场相机成像性能的主要指标除了传统的图像分辨率和FOV（FieldOfView）之外，还包括角度分辨率和FOP（FieldOfParallax）。其中FOP表示物体上某点发出的光线能进入相机光圈的角度范围，角度分辨率表示一束光线在FOP范围内被分割成的数量。目前市面上主流的消费级光场相机是基于微透镜阵列的光场采集，即在传统相机的成像传感器和镜头之间加入一片微透镜阵列。如图所示，物体上一点在FOP内的光线被微透镜分成4X4束，即该光场相机的角度分辨率为4X4，相机针对该点会同时采集16个方向的光，并记录成16个像素。视点图像分辨率与光场相机的角度分辨率息息相关，角度分辨率表征了被采集场景的离散化程度，角度分辨率越大，相机采集物体的细节越多，但同时会降低视点图像的分辨率，所以同时兼顾视点图像分辨率和物体细节，必须同时提高成像传感器的分辨率和微透镜数量。然而目前单相机成像传感器分辨率很难做的特别高（一般8K已达极限），所以每个视点图像分辨率一般只有480P左右。受限于单相机成像传感器分辨率，基于微透镜阵列的光场采集产生的数据量与传统相机相当。消费级光场相机体积一般较小，受限于空间，相机的FOP、角度分辨率、视点图像分辨率也相对较小，物体的细节很难详细的记录。所以，专业级的光场相机，一般采用相机阵列结构，即用多个相机规则排列，替代原先的微透镜，这样不仅可以提高FOP，也有足够的空间去排布相机，从而提高角度分辨率。


基于相机阵列的光场采集，角度分辨率为相机的数量，视点图像的分辨率为单个相机的分辨率，所以视点图像的分辨率可以达到很高（如2K、4K等），实际物体可以被真实地记录下来，但数据量会变得巨大，为N*单个相机数据量（N为相机数量，为几十至数百个；单个相机数据量，以4K为例，达到6-12Gbps）。如果在本地对内容进行建模，原始数据压缩率可达千倍，压缩至Gbps甚至数百Mbps。但所需的本地服务器非常昂贵，需要数十台配置高端显卡的服务器，成本达百万以上。未来可以采用本地+云端协同制作的方式，降低本地服务器成本，这对网络带宽和时延带来了巨大的挑战。目前光场显示技术更多局限于单层屏幕显示，如手机屏幕、VR/AR屏幕等，无法发挥光场内容多视角、多层对焦的优势。例如，人眼分别观看近处物体和远处物体时，所聚焦的平面是不同的，但在单层屏幕显示时，近处物体和远处物体实际只能成像在同一平面，会与人脑感知冲突，长期观看会产生视疲劳。多层平面是光场显示发展的趋势，届时，一幅图像中的近景可以显示在离人眼近的屏幕，远景显示在离人眼远的屏幕，高度还原人眼观看现实世界，该项技术已经逐步应用到VR/AR屏幕，如MagicLeapOne。除了多平面显示，光场显示还可以实现多视点。当前电视只能做到特定视角显示，用户在不同的位置看到的都是同一副画面。应用光场技术，当用户移动视线时，能够感受到画面角度的变化，使观影更加逼近现实视觉体验，目前，业界已经可以做到45个视点显示。随着显示技术的发展，多视点光场显示技术将更加成熟，未来摆在家里客厅的将不是4K/8K电视，而是4K/8K多视点电视，与此同时，网络需求也会将随着视点的增加而翻倍。


光场的最佳显示形态是裸眼全息，不需要借助VR/AR等辅助设备，直接就能看到3D立体全息影像。《阿凡达》是一部经典的科幻电影，其中三维全息沙盘给观众留下了深刻印象，这就是光场的全息显示形态，也是人眼追求的最佳视觉体验。全息显示的应用场景很广，如全息会议、全息通讯、全息演唱会等。目前远程会议主要以电话会议、视频会议为主，参与感不强，而利用全息技术，可以将全球各地的与会人的全息影像传输到会议室，仿佛在面对面讨论问题；该技术还可以应用在通讯领域，通过全息技术将远方的亲人带到你的面前；在全息演唱会领域，目前业界已有一些尝试，如初音演唱会、邓丽君演唱会、迈克杰克逊演唱会等，但受限于技术，该类演唱会都是通过全息膜投影的显示方式，并不是“真”全息，随着全息技术的不断发展，未来将摆脱全息膜，通过投影的方式直接显示出更加立体、更加逼近现实场景的画面，给用户带来更加震撼的视觉体验。


随着人眼视觉体验需求的提升，无论4K/8K平面视频、VR/AR，还是光场、裸眼全息，从内容制作到最终呈现，数据量越来越大，借助云端计算和云端渲染，通过网络分发给终端用户是未来应用的必然趋势。此时不同视觉体验下的内容对网络的诉求亦不同。例如在IPTV早期时期，标清画质下10M家庭带宽即可满足，而在高清、超高清出现后，家庭宽带需升级至20M~100M才可满足用户的极致体验。现在，VR逐渐进入人们的视野，网络又将迎来新一轮变革。上世纪90年代末，电信运营商家庭宽带业务起步。从早期拨号上网开始，20年来经历了从铜线到光纤入户的几代网络升级。在我国，截至2018年6月，全国固定宽带接入端口总数达到8.3亿个，覆盖全国所有城市、乡镇以及96%以上的行政村。光纤到户成为主要的宽带接入技术，光纤端口在固定宽带接入端口中所占比例提升至86.3%，标志着我国固定宽带网络全面进入光纤时代。从宽带速率上看，业务发展与网络建设亦相辅相成。在IPTV之前，家庭宽带以上网为主，宽带速率以10M以下为主流。2004年，IPTV率先在黑龙江试点以后，视频成为创新型业务，各式各样的视频盒子涌现，加速了网络升级。而“宽带中国”的国家战略的提出，以及IPTV牌照发放成为网络建设的催化剂，FTTB/FTTH普及水平快速攀升。与此同时，电视屏幕尺寸越做越大，分辨率越来越高，高清、超高清4K视频优势得到充分展现，又促进了家庭宽带速率的再次升级。根据中国信息通讯研究院发布的《中国宽带发展白皮书》中统计的数据显示，我国50Mbps及以上的固定宽带用户达3亿户，占全国固定宽带用户数80.5%；100Mbps及以上用户达2亿户，占比53.3%，说明平面视频时代下，百兆宽带成为家庭用户的刚需。2018年，CloudVR新业务在以华为iLab为中心的VROpenLab产业联盟推动下，成功在运营商网络中实现应用实践，开启了运营商从平面视频业务向三维沉浸式业务延伸的新篇章，也意味着家庭宽带速率将进一步提升，千兆家宽时代来临。


而对于移动网络，若智能手机的爆发开启了移动通讯的新时代，各种应用的涌现填充了4G网络的管道。如果说视频是4G网络的典型应用，那么在5G风口之下，VR/AR将迎来崭新的时代。超高清4K视频当前产业链已经非常成熟，对于运营商网络的传输要求在业界基本达成共识。从数据中可以看出，百兆的品质宽带可基本满足运营级4K体验要求，若要体验极致4K，在考虑家庭中其他娱乐应用及网络开销的情况下，带宽需要升级至200M甚至更高。8K大屏出现以后，其电视尺寸接近4K电视的2倍。在家庭应用中，相同距离条件下，视场角加大，临场感更强。从分辨率角度看，数据量相比4K则提升4倍。目前，8K分辨率的内容制作和播放尚处在探索培育期，产业上编解码标准尚未统一。除H.265标准可支持8K视频的编解码外，AVS3亦被看作是8K视频编解码标准之一。2019年3月，数字音视频编解码技术（AVS）标准工作组宣布完成了AVS3的起草工作,编码效率比AVS2视频标准提高1倍。由此可以预见，8K视频的带宽需求至少是4K视频的2倍以上。


对于VR内容，全景8K的视觉体验仅仅相当于传统TV的480P体验，若要达到4KTV的极致体验，需要VR全景分辨率达到24K，对于带宽的需求也是指数上升。不仅如此，VR的强交互属性还为网络带来了时延上的挑战。在强交互的VR业务中，MTP≤20ms才可以保障用户在使用过程中没有眩晕感。而渲染、计算上云之后，VR内容经过云渲染及流化，通过网络传输到终端解码显示，无形中加大了端到端处理时延。经过商业实践，采用端云异步渲染技术，可以放宽对网络的时延指标诉求。端云异步渲染技术是通过将云渲染及流化、终端刷新显示两个串行过程转为并行处理，即VR终端每次刷新画面时，使用云渲染平台送来的第n帧渲染帧作为基础帧进行二次投影，同时，云渲染平台处理第n+1帧渲染帧，与VR终端并行处理。此时，MTP由终端来决定，不依赖网络和云渲染，从而满足MTP时延要求。


虽然云渲染及网络时延不再影响MTP，但是时延依然影响用户的画面视觉体验。当时延过大时，会出现转头黑边和画面扭曲等问题，因此云端处理和网络传输时延依然需要约束。根据实验室测试分析，在理想体验阶段，云渲染及流化时延需要≤30ms。光场的极致视觉体验需要多层显示平面来呈现深度信息，所以同等分辨率、帧率下，光场显示需要的网络带宽将成几倍、甚至几十倍增长，如果用本身信息量就很大的VR/AR来显示光场内容，网络带宽需求将变得更大，若使用全息光场显示，则更是需要太赫兹频段的6G或万兆~太兆宽带网络承载。对于存在交互的业务，还需要保障网络端到端时延在40ms以内，强交互内容，如游戏，需保障时延在20ms以内。
异步扭曲、反畸变，点亮屏幕


面对极致的4K/8K平面视频体验，家庭网络带宽需求至少需要200M。对于用户侧，除了接入带宽，Wi-Fi也是影响体验的重要因素，802.11ac标准通过引入更宽射频带宽和高阶调制技术，将传输速度提升到1.73Gbps，从而保证Wi-Fi网络吞吐量。在接入侧，从表7-3中可以看出，即使1:32分光比下，GPON也仅能提供156Mbps/用户的带宽，长远来看，GPON升级10GPON成为是必然选择。


对于CloudVR业务，起步阶段网络需求与4K/8K平面视频接近，可以复用现有网络架构。但随着CloudVR的应用普及，人们追求极致体验的自然诉求将变得突出，更高清、零延迟、无花屏的极致体验在商业竞争中将更具优势。此时，CloudVR对网络的带宽和时延需求更加严格，家庭宽带套餐需要提升到千兆。同时，为了保障超低时延，网络架构面临升级，CDN下沉和边缘计算是解决时延的有效必要手段。确定性低时延Wi-Fi配合全光网络是未来CloudVR极致体验下的目标网络。在目标网络中，家庭侧高性能的Wi-Fi是家庭段的基础保障。从标准上，802.11ac虽然将空口速率提升至Gbit以上，但遗憾的是只支持5GHz频段，而且Wi-Fi在网络中的性能表现不仅仅是空口速度，家庭复杂环境将造成Wi-Fi信号大幅衰减，多人接入条件下的网络拥塞都将导致Wi-Fi效率直线下降。


下一代Wi-Fi需要解决更多终端的接入导致整个Wi-Fi网络效率降低的问题，Wi-Fi6（802.11ax）标准将引入上行MU-MIMO、OFDMA频分复用、1024-QAM高阶编码等技术，将从频谱资源利用、多用户接入等方面解决网络容量和传输效率问题。在密集用户环境中，Wi-Fi6将用户的平均吞吐量相比802.11ac提高至少4倍，并发用户数提升3倍以上，因此，Wi-Fi6(802.11ax)在面向CloudVR规模商用时将更具竞争力。同时，AP、ONT侧进行空口网络切片也是保障业务体验的有效手段。根业务优先级不同将空口划分为竞争型空口切片和保证型空口切片，针对上网业务选择竞争型空口切片转发，而对VR高优先级业务则选择保证型空口切片进行确定性时延的处理，保障用户体验。在接入段，随着CloudVR的规模部署，千兆家宽推广普及，现网局端采用GPON作为接入点将难以满足CloudVR业务体验需求，10GPON的应用将成为运营商网络升级的必然选择，根据测算，10GPON在1:32的分光比下，可以满足12K的CloudVR业务体验，匹配网络3~5年的发展。在承载网一侧，未来网络可能呈现多样性。对于时延极其敏感的强交互CloudVR业务，极致体验下，网络传输时延需控制在8ms以内。根据中国电信《低时延光网络技术白皮书》，光网络是目前主流通信技术中具有最低时延优势的技术，而且光网络电路时延具有良好的可预测性。根据时延比较示意图，可见层次越低，处理时延越小。从量级来看，L0层网元引入时延ns级、L1层网元引入时延us级、L2/L3层网元引入时延ms级、光纤引入时延与传输距离成正比（5us/km）。


而基于波分复用技术的OTN设备，其设备处理信息的层级位于最底部的L0和L1层，时延接近物理极限且可以承诺稳定的时延值。尤其在全光网络传输的条件下，将满足理想级CloudVR的业务体验，甚至更低时延的业务需求。在光场显示阶段，庞大的数据能够真实的还原现实场景，给用户提供极限的视觉体验，此时对网络传输的需求挑战更大，而随着科学技术的高速发展和光电器件成本的逐渐降低，整个网络架构将可能发生颠覆性的改变，并具备如下三个关键特征：以摩尔定律驱动带宽升级网络需要引入摩尔定律加速技术创新进程，实现全光网络设备容量的周期性提升，实现单比特成本的持续性下降，有效支撑各类创新性业务的带宽诉求。极简站点网络需要持续简化网络层次，提升站点集成度，大幅降低网络建设成本，包括机房空间、设备和空调的功耗、人工连纤和调度的成本。向自动驾驶网络演进网络需要具备自动化、智能化能力，可以支撑新业务的敏捷发放，缩短新业务上线时间；同时支持智能运维，通过故障的精准预测和自动定位，有效降低OPEX，为最终用户提供端到端的体验保障。


从技术上看，在家庭段，光纤入户已经承载不了Tbps级别的数据量，此时需要光纤到桌面、光纤到房间等网络方案，同时家庭Wi-Fi也需要通过60GHz或更高频段来承载。在城域，ITU-T定义的G.698.4（前G.metro）是一种值得期待的城域接入型技术，基于低成本可调谐激光器，具备端口无关特性，可以做到波长自适应，极大简化网络建设和运行维护，降低网络总体拥有成本（TCO）。在承载网上，距离达到光纤的传输极限还很遥远，尤其是在现实网络中，无论是容量、距离还是功耗，都还有很大潜力。未来借助更先进的芯片制造工艺，并持续优化算法，将进一步提升现实网络的传输能力，降低传输功耗。此外无损速率调整、动态带宽设置、芯片级AI功能等等，将成为自动驾驶网络的重要组成部分。


回顾通信与电子行业的发展，每10至15年会产生一次颠覆性变革，从IBM发布PC，实现个人电脑普及，到各大门户网站与网络论坛开启互联网的热潮、移动互联网席卷全球，再到现在Facebook、Wechat、Netflix等App成为主流信息媒介。新的终端平台孕育新的应用平台，新的应用平台又让终端平台变得更有价值，在不久的未来，VR/AR有潜力成为下一个终端平台。但是，目前的VR/AR设备普遍存在一些问题，用户体验需要提升。更高性能的网络将赋能VR/AR的发展。首先，速率大幅提升，VR/AR终端将不再需要过高的本地计算需求，云端即可完成大部分数据处理，节省了本地存储和计算的硬件要求，极大地减少了设备的体积、重量和成本。同时产品形态也将得到改善，更适合长时间使用和佩戴。其次，终端的改变必然带来交互的升级。在下一代计算平台中，我们需要一个全新的人机交互界面，不同于电脑的键盘鼠标和手机的屏幕点触等方式，VR/AR应用将创造更贴近自然的人机交互模式。再次，交互的中心也将发生转移，新的交互模式将是“以人为本”的交互方式。人机界面经历了命令字符式界面，到Windows图形界面，再到当前的移动端的Android/IOS图形用户界面。从显示维度来说，人机交互的方式已经从无图形发展到二维图形显示，现在二维图形显示将向高画质发展，同时在不久的将来将朝着三维全息显示发展，更符合人类的自然视觉体验。传统“人操作有限指令-机器被动响应有限信息”的交互模式将过渡为“数字模拟全部信息-人主动选择所需内容”的模式。传统的单屏幕-桌面显示将消失，目之所及就是操作界面。而且，人机交互无需特殊学习，只需使用自然交互习惯，如对话、手势、视觉等方式，交互的效率得到极大提升。未来，伴随着通信技术/显示技术的发展，内容也将被重新定义，朝着多维、多向互动发展，从而构建一个3D物联网。在3D物联网中，数字世界突破手机、电脑屏幕的束缚，与现实世界互相融合。3D物联网，不仅带来了内容形态的变化，更是让互联网世界进化为一个可以共享、互动、协作的空间。从黑白到彩色，从标清到高清，显示产业经历着一轮又一轮的技术革命。随着双G时代的开启，超高清、大尺寸将是未来家庭场景显示的核心，柔性AMOLED、VR/AR将会是未来显示技术的关键。而光场、全息将进一步提升显示技术对网络的需求，未来万兆至太兆宽带或6G移动网络才可承载，届时《头号玩家》里虚拟与现实世界并存、《阿凡达》里三维全息沙盘将不再是梦想。作为全球半导体显示领军企业，京东方始终致力于引领显示端口升级，愿开放应用端和技术端，将携手业界伙伴，共同推动显示与电子科技产业的技术创新与应用，构建共创共赢产业生态。iLab是华为超宽带网络创新实验室，致力于场景、体验、生态和友好网络的研究，从用户场景和体验角度研究网络友好性，从网络影响角度研究产业和生态。愿与产业链伙伴一起推动业务和技术创新、促进产业发展和开放的行业生态系统，为共建更美好的全联接世界贡献力量。




版权所有(cid:7713)华为技术有限公司、京东方科技集团股份有限公司2018。保留一切权利。
非经本公司书面许可，任何单位和个人不得擅自摘抄、复制本文档内容的部分或全部，并不得以任何形式传播。和其他华为商标均为华为技术有限公司的商标。和其他BOE商标均为京东方科技集团股份有限公司的商标。本文档提及的其他所有商标或注册商标，由各自的所有人拥有。您购买的产品、服务或特性等应受华为、京东方商业合同和条款的约束，本文档中描述的全部或部分产品、服务或特性可能不在您的购买或使用范围之内。除非合同另有约定，华为、京东方对本文档内容不做任何明示或暗示的声明或保证。由于产品版本升级或其他原因，本文档内容会不定期进行更新。除非另有约定，本文档仅作为使用指导，本文档中的所有陈述、信息和建议不构成任何明示或暗示的担保。
